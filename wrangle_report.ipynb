{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used for the analysis was spread over three datasets. The first source was an archive of tweets from WeRateDogs. The second source contained dog image predictions from a neural network and the third source was favourite and retweet data available on Twitter.\n",
    "\n",
    "The first step of the wrangling process involved gathering all this data. The archive of tweets was avaialable as a .csv file, and was read in as pandas dataframe using the pd.read_csv() method. The image predicitions were hosted on Udacity's server. This was downloaded programetically using python's requests library. As the archive of tweets did not have favourite and retweet info, I had to query this information using Twitter's API. The data returned was in json format and was read in line by line into a python list of dictionaries. Once this was done, the list was converted into a pandas dataframe using pd.DataFrame().\n",
    "\n",
    "The next step of the wrangling process was assessing and cleaning this data, both visually and programatically. Each of the dogs were classified into a certain dog stage: 'doggo','pupper', 'puppo' or 'floofer'. However, the dog stages each had their own column. To make the data tidy, a single column was created that showed the dog stage for each tweet. The three dataframes were also merged into one using the pd.merge() method. After cleaning the data for tidiness, I assessed it for quality issues. There were several columns that were changed into a different dtype. Amongst them, the date was changed from a string to a datetime object so it be parsed easily, and the favourite/ retweet counts were changed from a float to an int dype, as they can only be whole numbers. There were alot of rows that didn't have any dog names or have incorrect words such as 'by', 'the' etc. These values were change to np.nan using the str.islower() method. While the numerator could be higher than the denominator for dog ratings for this case, there were rows where the numerators were extremely high. Moreover, the denominators were not always ten. To correct this issue, I extracted the numerators again using python's regular expressions and the re library. There were a few outliers present that were looked into more closely and dropped after comparing it with the rest of the values.\n",
    "\n",
    "After wrangling the data, I had a clean dataset for my analysis. I wanted to know more about the dog names, the stages that they were in and the tweets that were most liked by users. From my analysis, the most popular dog names were 'Cooper', 'Oliver' and 'Charlie', and most of the dogs were in the 'pupper' stage. The most favourited tweet was about a video of a dog playing in a pool. The tweet read, 'Here's a doggo realizing you can stand in a pool. 13/10 enlightened af (vid by Tina Conrad) https://t.co/7wE9LTEXC4'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
